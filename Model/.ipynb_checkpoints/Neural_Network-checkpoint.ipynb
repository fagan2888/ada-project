{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../features/features_global.csv\", sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      7037\n",
       "purple    6696\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:,0].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_nulls = df.apply(lambda row : \n",
    "          any([ e == (\"null\") for e in row ])\n",
    "       , axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>purple</td>\n",
       "      <td>3032929911</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>394.617</td>\n",
       "      <td>1.92308</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>2.78571</td>\n",
       "      <td>158539</td>\n",
       "      <td>21724.8</td>\n",
       "      <td>24917.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30202.8</td>\n",
       "      <td>531.632</td>\n",
       "      <td>5.44737</td>\n",
       "      <td>5.03158</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>-0.242105</td>\n",
       "      <td>260.316</td>\n",
       "      <td>413.189</td>\n",
       "      <td>-8.27895</td>\n",
       "      <td>1.35263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0           1         2        3        4         5        6    \\\n",
       "212  purple  3032929911  0.428571  394.617  1.92308  0.923077  2.78571   \n",
       "\n",
       "        7        8        9     ...         162      163      164      165  \\\n",
       "212  158539  21724.8  24917.4   ...     30202.8  531.632  5.44737  5.03158   \n",
       "\n",
       "          166       167      168      169      170      171  \n",
       "212  0.363158 -0.242105  260.316  413.189 -8.27895  1.35263  \n",
       "\n",
       "[1 rows x 172 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[212]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13733,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~no_nulls]\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>2984814498</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>423.95993</td>\n",
       "      <td>1.917431</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>133402.100</td>\n",
       "      <td>17926.000</td>\n",
       "      <td>16480.800</td>\n",
       "      <td>...</td>\n",
       "      <td>13711.350</td>\n",
       "      <td>114.10000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.685000</td>\n",
       "      <td>-0.402500</td>\n",
       "      <td>-0.352500</td>\n",
       "      <td>193.48500</td>\n",
       "      <td>332.70502</td>\n",
       "      <td>-10.030000</td>\n",
       "      <td>-7.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>3034035764</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>402.25280</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>137797.310</td>\n",
       "      <td>17697.053</td>\n",
       "      <td>17959.790</td>\n",
       "      <td>...</td>\n",
       "      <td>17441.264</td>\n",
       "      <td>302.21054</td>\n",
       "      <td>1.189474</td>\n",
       "      <td>1.642105</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.081579</td>\n",
       "      <td>200.77895</td>\n",
       "      <td>350.03687</td>\n",
       "      <td>4.418421</td>\n",
       "      <td>30.384210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purple</td>\n",
       "      <td>3036731710</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>421.79210</td>\n",
       "      <td>2.215569</td>\n",
       "      <td>1.215569</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>154794.270</td>\n",
       "      <td>23505.592</td>\n",
       "      <td>24949.682</td>\n",
       "      <td>...</td>\n",
       "      <td>29733.684</td>\n",
       "      <td>782.63160</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>-0.036842</td>\n",
       "      <td>-0.413158</td>\n",
       "      <td>223.42105</td>\n",
       "      <td>339.43683</td>\n",
       "      <td>-9.331579</td>\n",
       "      <td>-31.594736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purple</td>\n",
       "      <td>3018436026</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>384.25073</td>\n",
       "      <td>1.917526</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>136257.270</td>\n",
       "      <td>17298.736</td>\n",
       "      <td>18882.053</td>\n",
       "      <td>...</td>\n",
       "      <td>14255.750</td>\n",
       "      <td>136.25000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>165.56500</td>\n",
       "      <td>310.27000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>65.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3026930091</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>398.31564</td>\n",
       "      <td>2.887755</td>\n",
       "      <td>1.887755</td>\n",
       "      <td>4.173913</td>\n",
       "      <td>125274.305</td>\n",
       "      <td>17986.130</td>\n",
       "      <td>22280.957</td>\n",
       "      <td>...</td>\n",
       "      <td>16022.895</td>\n",
       "      <td>226.68420</td>\n",
       "      <td>7.163158</td>\n",
       "      <td>6.894737</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.323684</td>\n",
       "      <td>288.94210</td>\n",
       "      <td>461.35263</td>\n",
       "      <td>24.378946</td>\n",
       "      <td>56.265793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1         2          3         4         5         6    \\\n",
       "0    blue  2984814498  0.650000  423.95993  1.917431  0.917431  2.900000   \n",
       "1  purple  3034035764  0.526316  402.25280  2.000000  1.000000  2.157895   \n",
       "2  purple  3036731710  0.409091  421.79210  2.215569  1.215569  3.636364   \n",
       "3  purple  3018436026  0.473684  384.25073  1.917526  0.917526  2.368421   \n",
       "4    blue  3026930091  0.478261  398.31564  2.887755  1.887755  4.173913   \n",
       "\n",
       "          7          8          9      ...            162        163  \\\n",
       "0  133402.100  17926.000  16480.800    ...      13711.350  114.10000   \n",
       "1  137797.310  17697.053  17959.790    ...      17441.264  302.21054   \n",
       "2  154794.270  23505.592  24949.682    ...      29733.684  782.63160   \n",
       "3  136257.270  17298.736  18882.053    ...      14255.750  136.25000   \n",
       "4  125274.305  17986.130  22280.957    ...      16022.895  226.68420   \n",
       "\n",
       "        164       165       166       167        168        169        170  \\\n",
       "0  1.190000  1.685000 -0.402500 -0.352500  193.48500  332.70502 -10.030000   \n",
       "1  1.189474  1.642105  0.100000 -0.081579  200.77895  350.03687   4.418421   \n",
       "2  0.326316  0.773684 -0.036842 -0.413158  223.42105  339.43683  -9.331579   \n",
       "3  0.235000  0.405000 -0.330000 -0.022500  165.56500  310.27000   0.042500   \n",
       "4  7.163158  6.894737  0.857895  0.323684  288.94210  461.35263  24.378946   \n",
       "\n",
       "         171  \n",
       "0  -7.407500  \n",
       "1  30.384210  \n",
       "2 -31.594736  \n",
       "3  65.232500  \n",
       "4  56.265793  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13660, 172)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = df.replace(to_replace='null', value=0)\n",
    "#df = df.replace(to_replace='infinity', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global constants\n",
    "seed = 7875\n",
    "validation_size = 750\n",
    "feature_count = df.shape[1] - 2\n",
    "\n",
    "#feed forward neural net\n",
    "n_nodes_hl1 = 200\n",
    "n_nodes_hl2 = 100\n",
    "n_nodes_hl3 = 50\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 20\n",
    "\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = np.asarray(df.ix[:,2:feature_count+2])\n",
    "#standardize X\n",
    "meanX = np.mean(X, axis = 0)\n",
    "stdX = np.std(X, axis = 0)\n",
    "\n",
    "f = open('mean.pckl', 'wb')\n",
    "pickle.dump(meanX, f)\n",
    "f.close()\n",
    "\n",
    "f = open('std.pckl', 'wb')\n",
    "pickle.dump(stdX, f)\n",
    "f.close()\n",
    "\n",
    "X = (X - meanX) / stdX\n",
    "\n",
    "Y_1 = np.asarray(df.ix[:,0])\n",
    "Y_1 = [int(y == \"purple\") for y in Y_1]\n",
    "#one hot Y\n",
    "Y = np.zeros(shape=(len(Y_1), n_classes))\n",
    "Y[np.arange(len(Y_1)), Y_1] = 1\n",
    "    \n",
    "validation_features = X[:validation_size]\n",
    "validation_labels = Y[:validation_size]\n",
    "\n",
    "train_features = X[validation_size:]\n",
    "train_labels = Y[validation_size:]\n",
    "\n",
    "num_examples = train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    \n",
    "    dropout_prob = 0.5\n",
    "    \n",
    "    hidden_1_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([feature_count, n_nodes_hl1], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl1]))\n",
    "    }\n",
    "    \n",
    "    hidden_2_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_nodes_hl2], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl2]))\n",
    "    }\n",
    "    \n",
    "    hidden_3_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl2, n_nodes_hl3], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl3]))\n",
    "    }\n",
    "    \n",
    "    output_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl3, n_classes], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_classes]))\n",
    "    }\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu6(l1)\n",
    "    \n",
    "    l1_drop = tf.nn.dropout(l1, dropout_prob, seed=seed)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1_drop, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu6(l2)\n",
    "    \n",
    "    l2_drop = tf.nn.dropout(l2, dropout_prob, seed=seed)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.sigmoid(l3)\n",
    "    \n",
    "    l3_drop = tf.nn.dropout(l3, dropout_prob, seed=seed)\n",
    "    \n",
    "    output = tf.matmul(l3_drop, output_layer['weights']) +  output_layer['biases']\n",
    "    \n",
    "    regularizers = (tf.nn.l2_loss(hidden_1_layer['weights']) + tf.nn.l2_loss(hidden_1_layer['biases']) +\n",
    "                        tf.nn.l2_loss(hidden_2_layer['weights']) + tf.nn.l2_loss(hidden_2_layer['biases']) +\n",
    "                            tf.nn.l2_loss(hidden_3_layer['weights']) + tf.nn.l2_loss(hidden_3_layer['biases']) +\n",
    "                                tf.nn.l2_loss(output_layer['weights']) + tf.nn.l2_loss(output_layer['biases']))\n",
    "    \n",
    "    return output, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stat(x_range, trains, tests, vals, acc_0s, acc_1s):\n",
    "    \n",
    "    #plt.plot(x_range, trains,'-b', label='Training acc')\n",
    "    #plt.plot(x_range, vals,'-g', label='Validation acc')\n",
    "    #plt.plot(x_range, tests,'-y', label='Test acc')\n",
    "    plt.plot(x_range, acc_0s,'-r', label='Acc Class 0')\n",
    "    plt.plot(x_range, acc_1s,'-k', label='Acc Class 1')\n",
    "\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.0)\n",
    "\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_CV(x, lambda_):\n",
    "    \n",
    "    vals = []\n",
    "    trains = []\n",
    "    tests = []\n",
    "    x_range = []\n",
    "    \n",
    "    f1_vals = []\n",
    "    \n",
    "    acc_1s = []\n",
    "    acc_0s = []\n",
    "    \n",
    "    prediction, regularizers = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "    #log_loss = tf.contrib.losses.log_loss(predictions=prediction, labels=y)\n",
    "\n",
    "    #Eval this to get probability of [winning,losing]\n",
    "    prob = tf.nn.softmax(prediction)\n",
    "    \n",
    "    #learning rate can be passed\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost + lambda_ * regularizers)\n",
    "    \n",
    "    #metrics\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    false_prediction = tf.logical_not(correct_prediction)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "    #use for f1 score if needed\n",
    "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n",
    "    #acc for each class\n",
    "    class_0 = tf.where(tf.equal(tf.argmax(y, 1), 0))\n",
    "    class_0 = tf.reshape(class_0, [tf.shape(class_0)[0]])\n",
    "    pred_0 = tf.gather(prediction, class_0)\n",
    "    y_0 = tf.gather(y, class_0)\n",
    "    class_0_correct = tf.equal(tf.argmax(pred_0,1), tf.argmax(y_0,1))\n",
    "    acc_0 = tf.reduce_mean(tf.cast(class_0_correct, 'float'))\n",
    "    \n",
    "    class_1 = tf.where(tf.equal(tf.argmax(y, 1), 1))\n",
    "    class_1 = tf.reshape(class_1, [tf.shape(class_1)[0]])\n",
    "    pred_1 = tf.gather(prediction, class_1)\n",
    "    y_1 = tf.gather(y, class_1)\n",
    "    class_1_correct = tf.equal(tf.argmax(pred_1,1), tf.argmax(y_1,1))\n",
    "    acc_1 = tf.reduce_mean(tf.cast(class_1_correct, 'float'))\n",
    "    \n",
    "    display_step = 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            #epoch_loss = 0\n",
    "            fold_index = 0\n",
    "            \n",
    "            kf = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "            for train_index, test_index in kf.split(train_features, train_labels):\n",
    "                fold_index += 1\n",
    "                X_train, X_test = train_features[train_index], train_features[test_index]\n",
    "                y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: X_train, y: y_train})\n",
    "                #epoch_loss += c\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={ x: X_train, y: y_train})  \n",
    "                test_accuracy = accuracy.eval(feed_dict={ x: X_test, y: y_test})  \n",
    "                \n",
    "                # increase display_step after 10 iteration of same decimal\n",
    "                if epoch%(display_step*10) == 0 and epoch:\n",
    "                       display_step *= 10\n",
    "    \n",
    "                if (epoch%display_step == 0 or (epoch+1) == hm_epochs) and fold_index == 5:\n",
    "                    print('train:%.4f, test:%.4f,  epoch %d, fold %d' % (train_accuracy, test_accuracy, epoch, fold_index))\n",
    "\n",
    "                    #if (fold_index == kf.n_splits):\n",
    "                    validation_accuracy = accuracy.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "                    print ('val:%.2f' % (validation_accuracy))\n",
    "                    \n",
    "                    tp = true_positives.eval(feed_dict={ x: validation_features, y: validation_labels})   \n",
    "                    fp = false_positives.eval(feed_dict={ x: validation_features, y: validation_labels})  \n",
    "                    fn = false_negatives.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "\n",
    "                    precision = float(tp) / float(tp+fn + 0.0000000000001)\n",
    "                    recall = float(tp) / float(tp + fn + 0.0000000000001)\n",
    "                    F1_val = 2 * ( precision * recall ) / ( precision + recall + 0.0000000000001 )\n",
    "\n",
    "                    x_range.append(epoch)\n",
    "                    vals.append(validation_accuracy)\n",
    "                    trains.append(train_accuracy)\n",
    "                    tests.append(test_accuracy)\n",
    "                    f1_vals.append(F1_val)\n",
    "                    \n",
    "                    #print(validation_labels)\n",
    "                    #print(class_1.eval(feed_dict={ x: validation_features, y: validation_labels})  )\n",
    "\n",
    "                    acc_1s.append(acc_1.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    acc_0s.append(acc_0.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)        \n",
    "        \n",
    "        display_stat(x_range, trains, tests, vals, acc_0s, acc_1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.4860, test:0.4969,  epoch 0, fold 5\n",
      "val:0.47\n",
      "train:0.4863, test:0.4988,  epoch 1, fold 5\n",
      "val:0.46\n",
      "train:0.4854, test:0.4965,  epoch 2, fold 5\n",
      "val:0.47\n",
      "train:0.4887, test:0.5035,  epoch 3, fold 5\n",
      "val:0.48\n",
      "train:0.4894, test:0.5012,  epoch 4, fold 5\n",
      "val:0.47\n",
      "train:0.4956, test:0.4942,  epoch 5, fold 5\n",
      "val:0.48\n",
      "train:0.4969, test:0.4985,  epoch 6, fold 5\n",
      "val:0.48\n",
      "train:0.4987, test:0.5074,  epoch 7, fold 5\n",
      "val:0.50\n",
      "train:0.4997, test:0.5151,  epoch 8, fold 5\n",
      "val:0.50\n",
      "train:0.4992, test:0.4950,  epoch 9, fold 5\n",
      "val:0.51\n",
      "train:0.5041, test:0.5000,  epoch 10, fold 5\n",
      "val:0.52\n",
      "train:0.5109, test:0.5302,  epoch 19, fold 5\n",
      "val:0.50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFyCAYAAAC6HdP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYf4fsLuZ85jIoyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25dd56bae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, feature_count])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "model_path = \"./tmp2/model.ckpt\"\n",
    "save_dir = './tmp2/'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "    \n",
    "L2_lambda_ = 1.5e-3\n",
    "train_neural_network_CV(x, L2_lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability test [[ 0.38545015  0.61454988]]\n"
     ]
    }
   ],
   "source": [
    "# Running a new session to predict based on model\n",
    "#TODO make sure it works and test\n",
    "prediction, regularizers = neural_network_model(x)\n",
    "#Eval this to get probability of [winning,losing]\n",
    "prob = tf.nn.softmax(prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     saver.restore(sess, model_path)\n",
    "    new_saver = tf.train.import_meta_graph(model_path + \".meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./tmp2'))\n",
    "    \n",
    "    #test random sample from validation test\n",
    "    prob_test = validation_features[40].reshape((1,validation_features[0].shape[0]))\n",
    "    prob_value = prob.eval(feed_dict={ x:prob_test})  \n",
    "    print('probability test', prob_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32692872, -0.31204851, -0.32684987, -0.32688453, -0.32676454,\n",
       "        5.21943154,  0.50826235,  0.38402118, -0.31375633, -0.32673353,\n",
       "       -0.32671255, -0.32694888, -0.32693146, -0.31751632, -0.31180154,\n",
       "       -0.32656407, -0.32534424, -0.32692872, -0.31120542, -0.32684049,\n",
       "       -0.32687515, -0.32676819,  8.44878065,  0.94904214,  0.38893186,\n",
       "       -0.30494007, -0.32671912, -0.32670471, -0.32695061, -0.3269403 ,\n",
       "       -0.3168691 , -0.31103848, -0.32660903, -0.32516702, -0.32693602,\n",
       "       -0.31333459, -0.32688257, -0.32691723, -0.32682657,  3.58025366,\n",
       "        0.43102299,  0.67482447, -0.31463558, -0.32677403, -0.32673244,\n",
       "       -0.32695061, -0.32691869, -0.31811666, -0.31209724, -0.32695061,\n",
       "       -0.32602666, -0.32692689, -0.31192594, -0.32686835, -0.32690301,\n",
       "       -0.32682292,  5.78753747,  0.55221774,  0.5592773 , -0.30653076,\n",
       "       -0.3267972 , -0.32680522, -0.32692735, -0.32695061, -0.3169428 ,\n",
       "       -0.31257845, -0.32593181, -0.32630248, -0.3269351 , -0.31459225,\n",
       "       -0.32687734, -0.326912  , -0.32685019,  2.27890019,  0.26609751,\n",
       "        0.26042377, -0.31155673, -0.32688207, -0.32685833, -0.3269507 ,\n",
       "       -0.3269507 , -0.31912946, -0.31369608, -0.3269507 , -0.32537006,\n",
       "       -0.32693602, -0.31349467, -0.32688095, -0.32691561, -0.3268521 ,\n",
       "        4.10778626,  0.24002783,  0.40965818, -0.31650171, -0.32682474,\n",
       "       -0.32680249, -0.32695061, -0.32695061, -0.31767193, -0.31278076,\n",
       "       -0.32695061, -0.32695061, -0.3269351 , -0.31323972, -0.32687816,\n",
       "       -0.32691282, -0.32685539,  6.15701943,  0.5269805 ,  0.45189612,\n",
       "       -0.3139049 , -0.32673044, -0.32672022, -0.3269507 , -0.32694637,\n",
       "       -0.31819175, -0.31235719, -0.3269507 , -0.3269507 , -0.32693054,\n",
       "       -0.31278984, -0.32684381, -0.32687847, -0.32673718,  3.35458288,\n",
       "        0.55595   ,  0.40239613, -0.32191405, -0.32681197, -0.32680851,\n",
       "       -0.32694204, -0.32695061, -0.31696724, -0.31184769, -0.32506149,\n",
       "       -0.32470386, -0.32693164, -0.31240127, -0.32685428, -0.32688894,\n",
       "       -0.3267826 ,  4.66697398,  0.61270878,  0.39842881, -0.31358084,\n",
       "       -0.32678728, -0.32677411, -0.32692809, -0.32693484, -0.3163633 ,\n",
       "       -0.31168965, -0.32581041, -0.32581569, -0.32692325, -0.31527433,\n",
       "       -0.3268936 , -0.32692826, -0.32691048,  0.89425119, -0.05108737,\n",
       "        0.30523306, -0.31179533, -0.32690373, -0.32688603, -0.32694231,\n",
       "       -0.32692662, -0.32028214, -0.31461351, -0.32695061, -0.32489239])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
