{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../features/features.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global constants\n",
    "seed = 42\n",
    "validation_size = 10\n",
    "feature_count = df.shape[1] - 2\n",
    "\n",
    "#feed forward neural net\n",
    "n_nodes_hl1 = 25\n",
    "n_nodes_hl2 = 25\n",
    "n_nodes_hl3 = 25\n",
    "\n",
    "#cycles of feed forward + backprop\n",
    "hm_epochs = 200\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 8\n",
    "\n",
    "keep_rate = 0.8\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.asarray(df.ix[:,2:feature_count+2])\n",
    "Y_1 = np.asarray(df.ix[:,0])\n",
    "Y_1 = [int(y == \"purple\") for y in Y_1]\n",
    "#one hot Y\n",
    "Y = np.zeros(shape=(len(Y_1), n_classes))\n",
    "Y[np.arange(len(Y_1)), Y_1] = 1\n",
    "    \n",
    "validation_features = X[:validation_size]\n",
    "validation_labels = Y[:validation_size]\n",
    "\n",
    "train_features = X[validation_size:]\n",
    "train_labels = Y[validation_size:]\n",
    "\n",
    "num_examples = train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    \n",
    "    hidden_1_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([feature_count, n_nodes_hl1], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl1]))\n",
    "    }\n",
    "    \n",
    "    hidden_2_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_nodes_hl2], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl2]))\n",
    "    }\n",
    "    \n",
    "    hidden_3_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl2, n_nodes_hl3], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl3]))\n",
    "    }\n",
    "    \n",
    "    output_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl3, n_classes], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_classes]))\n",
    "    }\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.sigmoid(l3)\n",
    "    \n",
    "    output = tf.matmul(l3, output_layer['weights']) +  output_layer['biases']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "\n",
    "# serve data by batches\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    #meh\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    global train_features\n",
    "    global train_labels\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reordered randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_features = train_features[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "        \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return train_features[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    \n",
    "    prediction = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "    \n",
    "    #metrics\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    false_prediction = tf.logical_not(correct_prediction)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n",
    "    #learning rate can be passed\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    display_step = 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = next_batch(batch_size)\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "                \n",
    "                \n",
    "            # increase display_step after 10 iteration of same decimal\n",
    "            if epoch%(display_step*10) == 0 and epoch:\n",
    "                display_step *= 10\n",
    "                \n",
    "            if epoch%display_step == 0 or (epoch+1) == hm_epochs:\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={ x: train_features, y: train_labels})  \n",
    "                validation_accuracy = accuracy.eval(feed_dict={ x: validation_features, y: validation_labels})     \n",
    "                print('train accuracy => %.2f, validation accuracy => %.2f for epoch %d' % (train_accuracy, validation_accuracy, epoch))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 0\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 1\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 2\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 3\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 4\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 5\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 6\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 7\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 8\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 9\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 10\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 20\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 30\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 40\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 50\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 60\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 70\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 80\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 90\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 100\n",
      "train accuracy => 0.54, validation accuracy => 0.50 for epoch 199\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, feature_count])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network_CV(x):\n",
    "    \n",
    "    prediction = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "    \n",
    "    #metrics\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    false_prediction = tf.logical_not(correct_prediction)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n",
    "    #learning rate can be passed\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    display_step = 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            #epoch_loss = 0\n",
    "            \n",
    "            #train and acc summed over all folds\n",
    "            test_accs = []\n",
    "            train_accs = []\n",
    "            \n",
    "            kf = KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "            for train_index, test_index in kf.split(train_features, train_labels):\n",
    "                X_train, X_test = train_features[train_index], train_features[test_index]\n",
    "                y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: X_train, y: y_train})\n",
    "                #epoch_loss += c\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={ x: X_train, y: y_train})  \n",
    "                test_accuracy = accuracy.eval(feed_dict={ x: X_test, y: y_test})  \n",
    "                \n",
    "                train_accs.append(train_accuracy)\n",
    "                test_accs.append(test_accuracy)\n",
    "                \n",
    "            train_acc = np.sum(train_accs) / len(train_accs)\n",
    "            test_acc = np.sum(test_accs) / len(test_accs)\n",
    "            \n",
    "            # increase display_step after 10 iteration of same decimal\n",
    "            if epoch%(display_step*10) == 0 and epoch:\n",
    "                display_step *= 10\n",
    "                \n",
    "            if epoch%display_step == 0 or (epoch+1) == hm_epochs:\n",
    "                \n",
    "                validation_accuracy = accuracy.eval(feed_dict={ x: validation_features, y: validation_labels})     \n",
    "                print('train accuracy => %.2f, test acc =>  %.2f, validation accuracy => %.2f for epoch %d' % (train_acc, test_acc, validation_accuracy, epoch))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy => 0.49, test acc =>  0.47, validation accuracy => 0.50 for epoch 0\n",
      "train accuracy => 0.54, test acc =>  0.54, validation accuracy => 0.50 for epoch 1\n",
      "train accuracy => 0.54, test acc =>  0.54, validation accuracy => 0.50 for epoch 2\n",
      "train accuracy => 0.54, test acc =>  0.54, validation accuracy => 0.50 for epoch 3\n",
      "train accuracy => 0.54, test acc =>  0.54, validation accuracy => 0.50 for epoch 4\n",
      "train accuracy => 0.54, test acc =>  0.54, validation accuracy => 0.50 for epoch 5\n",
      "train accuracy => 0.54, test acc =>  0.55, validation accuracy => 0.50 for epoch 6\n",
      "train accuracy => 0.55, test acc =>  0.55, validation accuracy => 0.50 for epoch 7\n",
      "train accuracy => 0.56, test acc =>  0.57, validation accuracy => 0.40 for epoch 8\n",
      "train accuracy => 0.59, test acc =>  0.52, validation accuracy => 0.50 for epoch 9\n",
      "train accuracy => 0.59, test acc =>  0.56, validation accuracy => 0.60 for epoch 10\n",
      "train accuracy => 0.67, test acc =>  0.67, validation accuracy => 0.50 for epoch 20\n",
      "train accuracy => 0.71, test acc =>  0.68, validation accuracy => 0.70 for epoch 30\n",
      "train accuracy => 0.73, test acc =>  0.73, validation accuracy => 0.50 for epoch 40\n",
      "train accuracy => 0.75, test acc =>  0.73, validation accuracy => 0.50 for epoch 50\n",
      "train accuracy => 0.78, test acc =>  0.77, validation accuracy => 0.40 for epoch 60\n",
      "train accuracy => 0.82, test acc =>  0.82, validation accuracy => 0.50 for epoch 70\n",
      "train accuracy => 0.86, test acc =>  0.88, validation accuracy => 0.50 for epoch 80\n",
      "train accuracy => 0.90, test acc =>  0.87, validation accuracy => 0.50 for epoch 90\n",
      "train accuracy => 0.93, test acc =>  0.92, validation accuracy => 0.50 for epoch 100\n",
      "train accuracy => 1.00, test acc =>  1.00, validation accuracy => 0.50 for epoch 199\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, feature_count])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "train_neural_network_CV(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
