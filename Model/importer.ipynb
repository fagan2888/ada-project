{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = \"../Model/tmp\"\n",
    "\n",
    "seed = 42\n",
    "\n",
    "feature_count = 170\n",
    "\n",
    "#feed forward neural net\n",
    "n_nodes_hl1 = 200\n",
    "n_nodes_hl2 = 100\n",
    "n_nodes_hl3 = 50\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "x = tf.placeholder('float', [None, feature_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    \n",
    "    dropout_prob = 0.5\n",
    "    \n",
    "    hidden_1_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([feature_count, n_nodes_hl1], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl1]))\n",
    "    }\n",
    "    \n",
    "    hidden_2_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_nodes_hl2], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl2]))\n",
    "    }\n",
    "    \n",
    "    hidden_3_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl2, n_nodes_hl3], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl3]))\n",
    "    }\n",
    "    \n",
    "    output_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl3, n_classes], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_classes]))\n",
    "    }\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu6(l1)\n",
    "    \n",
    "    l1_drop = tf.nn.dropout(l1, dropout_prob, seed=seed)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1_drop, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu6(l2)\n",
    "    \n",
    "    l2_drop = tf.nn.dropout(l2, dropout_prob, seed=seed)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.sigmoid(l3)\n",
    "    \n",
    "    l3_drop = tf.nn.dropout(l3, dropout_prob, seed=seed)\n",
    "    \n",
    "    output = tf.matmul(l3_drop, output_layer['weights']) +  output_layer['biases']\n",
    "    \n",
    "    regularizers = (tf.nn.l2_loss(hidden_1_layer['weights']) + tf.nn.l2_loss(hidden_1_layer['biases']) +\n",
    "                        tf.nn.l2_loss(hidden_2_layer['weights']) + tf.nn.l2_loss(hidden_2_layer['biases']) +\n",
    "                            tf.nn.l2_loss(hidden_3_layer['weights']) + tf.nn.l2_loss(hidden_3_layer['biases']) +\n",
    "                                tf.nn.l2_loss(output_layer['weights']) + tf.nn.l2_loss(output_layer['biases']))\n",
    "    \n",
    "    return output, regularizers\n",
    "\n",
    "\n",
    "prediction, regularizers = neural_network_model(x)\n",
    "#Eval this to get probability of [winning,losing]\n",
    "prob = tf.nn.softmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = [[-0.32692872, -0.31204851, -0.32684987, -0.32688453, -0.32676454,\n",
    "        5.21943154,  0.50826235,  0.38402118, -0.31375633, -0.32673353,\n",
    "       -0.32671255, -0.32694888, -0.32693146, -0.31751632, -0.31180154,\n",
    "       -0.32656407, -0.32534424, -0.32692872, -0.31120542, -0.32684049,\n",
    "       -0.32687515, -0.32676819,  8.44878065,  0.94904214,  0.38893186,\n",
    "       -0.30494007, -0.32671912, -0.32670471, -0.32695061, -0.3269403 ,\n",
    "       -0.3168691 , -0.31103848, -0.32660903, -0.32516702, -0.32693602,\n",
    "       -0.31333459, -0.32688257, -0.32691723, -0.32682657,  3.58025366,\n",
    "        0.43102299,  0.67482447, -0.31463558, -0.32677403, -0.32673244,\n",
    "       -0.32695061, -0.32691869, -0.31811666, -0.31209724, -0.32695061,\n",
    "       -0.32602666, -0.32692689, -0.31192594, -0.32686835, -0.32690301,\n",
    "       -0.32682292,  5.78753747,  0.55221774,  0.5592773 , -0.30653076,\n",
    "       -0.3267972 , -0.32680522, -0.32692735, -0.32695061, -0.3169428 ,\n",
    "       -0.31257845, -0.32593181, -0.32630248, -0.3269351 , -0.31459225,\n",
    "       -0.32687734, -0.326912  , -0.32685019,  2.27890019,  0.26609751,\n",
    "        0.26042377, -0.31155673, -0.32688207, -0.32685833, -0.3269507 ,\n",
    "       -0.3269507 , -0.31912946, -0.31369608, -0.3269507 , -0.32537006,\n",
    "       -0.32693602, -0.31349467, -0.32688095, -0.32691561, -0.3268521 ,\n",
    "        4.10778626,  0.24002783,  0.40965818, -0.31650171, -0.32682474,\n",
    "       -0.32680249, -0.32695061, -0.32695061, -0.31767193, -0.31278076,\n",
    "       -0.32695061, -0.32695061, -0.3269351 , -0.31323972, -0.32687816,\n",
    "       -0.32691282, -0.32685539,  6.15701943,  0.5269805 ,  0.45189612,\n",
    "       -0.3139049 , -0.32673044, -0.32672022, -0.3269507 , -0.32694637,\n",
    "       -0.31819175, -0.31235719, -0.3269507 , -0.3269507 , -0.32693054,\n",
    "       -0.31278984, -0.32684381, -0.32687847, -0.32673718,  3.35458288,\n",
    "        0.55595   ,  0.40239613, -0.32191405, -0.32681197, -0.32680851,\n",
    "       -0.32694204, -0.32695061, -0.31696724, -0.31184769, -0.32506149,\n",
    "       -0.32470386, -0.32693164, -0.31240127, -0.32685428, -0.32688894,\n",
    "       -0.3267826 ,  4.66697398,  0.61270878,  0.39842881, -0.31358084,\n",
    "       -0.32678728, -0.32677411, -0.32692809, -0.32693484, -0.3163633 ,\n",
    "       -0.31168965, -0.32581041, -0.32581569, -0.32692325, -0.31527433,\n",
    "       -0.3268936 , -0.32692826, -0.32691048,  0.89425119, -0.05108737,\n",
    "        0.30523306, -0.31179533, -0.32690373, -0.32688603, -0.32694231,\n",
    "       -0.32692662, -0.32028214, -0.31461351, -0.32695061, -0.32489239]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "new_saver = tf.train.import_meta_graph(model_path + \"/model.ckpt.meta\")\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability test [[ 0.38545018  0.61454988]]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    prob_value = prob.eval(feed_dict={ x:test})\n",
    "    print('probability test', prob_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Model/tmp/model.ckpt.meta'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path + \"/model.ckpt.meta\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
