{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../features/features_global.csv\", sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      7002\n",
       "purple    6658\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:,0].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_nulls = df.apply(lambda row : \n",
    "          any([ e == (\"null\") for e in row ])\n",
    "       , axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>purple</td>\n",
       "      <td>3032929911</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>394.617</td>\n",
       "      <td>1.92308</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>2.78571</td>\n",
       "      <td>158539</td>\n",
       "      <td>21724.8</td>\n",
       "      <td>24917.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30202.8</td>\n",
       "      <td>531.632</td>\n",
       "      <td>5.44737</td>\n",
       "      <td>5.03158</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>-0.242105</td>\n",
       "      <td>260.316</td>\n",
       "      <td>413.189</td>\n",
       "      <td>-8.27895</td>\n",
       "      <td>1.35263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0           1         2        3        4         5        6    \\\n",
       "212  purple  3032929911  0.428571  394.617  1.92308  0.923077  2.78571   \n",
       "\n",
       "        7        8        9     ...         162      163      164      165  \\\n",
       "212  158539  21724.8  24917.4   ...     30202.8  531.632  5.44737  5.03158   \n",
       "\n",
       "          166       167      168      169      170      171  \n",
       "212  0.363158 -0.242105  260.316  413.189 -8.27895  1.35263  \n",
       "\n",
       "[1 rows x 172 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[212]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13733,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~no_nulls]\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>2984814498</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>423.95993</td>\n",
       "      <td>1.917431</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>133402.100</td>\n",
       "      <td>17926.000</td>\n",
       "      <td>16480.800</td>\n",
       "      <td>...</td>\n",
       "      <td>13711.350</td>\n",
       "      <td>114.10000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.685000</td>\n",
       "      <td>-0.402500</td>\n",
       "      <td>-0.352500</td>\n",
       "      <td>193.48500</td>\n",
       "      <td>332.70502</td>\n",
       "      <td>-10.030000</td>\n",
       "      <td>-7.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>3034035764</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>402.25280</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>137797.310</td>\n",
       "      <td>17697.053</td>\n",
       "      <td>17959.790</td>\n",
       "      <td>...</td>\n",
       "      <td>17441.264</td>\n",
       "      <td>302.21054</td>\n",
       "      <td>1.189474</td>\n",
       "      <td>1.642105</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.081579</td>\n",
       "      <td>200.77895</td>\n",
       "      <td>350.03687</td>\n",
       "      <td>4.418421</td>\n",
       "      <td>30.384210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purple</td>\n",
       "      <td>3036731710</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>421.79210</td>\n",
       "      <td>2.215569</td>\n",
       "      <td>1.215569</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>154794.270</td>\n",
       "      <td>23505.592</td>\n",
       "      <td>24949.682</td>\n",
       "      <td>...</td>\n",
       "      <td>29733.684</td>\n",
       "      <td>782.63160</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>-0.036842</td>\n",
       "      <td>-0.413158</td>\n",
       "      <td>223.42105</td>\n",
       "      <td>339.43683</td>\n",
       "      <td>-9.331579</td>\n",
       "      <td>-31.594736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purple</td>\n",
       "      <td>3018436026</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>384.25073</td>\n",
       "      <td>1.917526</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>136257.270</td>\n",
       "      <td>17298.736</td>\n",
       "      <td>18882.053</td>\n",
       "      <td>...</td>\n",
       "      <td>14255.750</td>\n",
       "      <td>136.25000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>165.56500</td>\n",
       "      <td>310.27000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>65.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3026930091</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>398.31564</td>\n",
       "      <td>2.887755</td>\n",
       "      <td>1.887755</td>\n",
       "      <td>4.173913</td>\n",
       "      <td>125274.305</td>\n",
       "      <td>17986.130</td>\n",
       "      <td>22280.957</td>\n",
       "      <td>...</td>\n",
       "      <td>16022.895</td>\n",
       "      <td>226.68420</td>\n",
       "      <td>7.163158</td>\n",
       "      <td>6.894737</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.323684</td>\n",
       "      <td>288.94210</td>\n",
       "      <td>461.35263</td>\n",
       "      <td>24.378946</td>\n",
       "      <td>56.265793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1         2          3         4         5         6    \\\n",
       "0    blue  2984814498  0.650000  423.95993  1.917431  0.917431  2.900000   \n",
       "1  purple  3034035764  0.526316  402.25280  2.000000  1.000000  2.157895   \n",
       "2  purple  3036731710  0.409091  421.79210  2.215569  1.215569  3.636364   \n",
       "3  purple  3018436026  0.473684  384.25073  1.917526  0.917526  2.368421   \n",
       "4    blue  3026930091  0.478261  398.31564  2.887755  1.887755  4.173913   \n",
       "\n",
       "          7          8          9      ...            162        163  \\\n",
       "0  133402.100  17926.000  16480.800    ...      13711.350  114.10000   \n",
       "1  137797.310  17697.053  17959.790    ...      17441.264  302.21054   \n",
       "2  154794.270  23505.592  24949.682    ...      29733.684  782.63160   \n",
       "3  136257.270  17298.736  18882.053    ...      14255.750  136.25000   \n",
       "4  125274.305  17986.130  22280.957    ...      16022.895  226.68420   \n",
       "\n",
       "        164       165       166       167        168        169        170  \\\n",
       "0  1.190000  1.685000 -0.402500 -0.352500  193.48500  332.70502 -10.030000   \n",
       "1  1.189474  1.642105  0.100000 -0.081579  200.77895  350.03687   4.418421   \n",
       "2  0.326316  0.773684 -0.036842 -0.413158  223.42105  339.43683  -9.331579   \n",
       "3  0.235000  0.405000 -0.330000 -0.022500  165.56500  310.27000   0.042500   \n",
       "4  7.163158  6.894737  0.857895  0.323684  288.94210  461.35263  24.378946   \n",
       "\n",
       "         171  \n",
       "0  -7.407500  \n",
       "1  30.384210  \n",
       "2 -31.594736  \n",
       "3  65.232500  \n",
       "4  56.265793  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13660, 172)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = df.replace(to_replace='null', value=0)\n",
    "#df = df.replace(to_replace='infinity', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global constants\n",
    "seed = 7875\n",
    "validation_size = 750\n",
    "feature_count = df.shape[1] - 2\n",
    "\n",
    "#feed forward neural net\n",
    "n_nodes_hl1 = 200\n",
    "n_nodes_hl2 = 100\n",
    "n_nodes_hl3 = 50\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 450\n",
    "\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = np.asarray(df.ix[:,2:feature_count+2])\n",
    "#standardize X\n",
    "meanX = np.mean(X, axis = 0)\n",
    "stdX = np.std(X, axis = 0)\n",
    "\n",
    "f = open('mean.pckl', 'wb')\n",
    "pickle.dump(meanX, f)\n",
    "f.close()\n",
    "\n",
    "f = open('std.pckl', 'wb')\n",
    "pickle.dump(stdX, f)\n",
    "f.close()\n",
    "\n",
    "X = (X - meanX) / stdX\n",
    "\n",
    "Y_1 = np.asarray(df.ix[:,0])\n",
    "Y_1 = [int(y == \"purple\") for y in Y_1]\n",
    "#one hot Y\n",
    "Y = np.zeros(shape=(len(Y_1), n_classes))\n",
    "Y[np.arange(len(Y_1)), Y_1] = 1\n",
    "    \n",
    "validation_features = X[:validation_size]\n",
    "validation_labels = Y[:validation_size]\n",
    "\n",
    "train_features = X[validation_size:]\n",
    "train_labels = Y[validation_size:]\n",
    "\n",
    "num_examples = train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    \n",
    "    dropout_prob = 0.5\n",
    "    \n",
    "    hidden_1_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([feature_count, n_nodes_hl1], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl1]))\n",
    "    }\n",
    "    \n",
    "    hidden_2_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_nodes_hl2], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl2]))\n",
    "    }\n",
    "    \n",
    "    hidden_3_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl2, n_nodes_hl3], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl3]))\n",
    "    }\n",
    "    \n",
    "    output_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl3, n_classes], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_classes]))\n",
    "    }\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu6(l1)\n",
    "    \n",
    "    l1_drop = tf.nn.dropout(l1, dropout_prob, seed=seed)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1_drop, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu6(l2)\n",
    "    \n",
    "    l2_drop = tf.nn.dropout(l2, dropout_prob, seed=seed)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.sigmoid(l3)\n",
    "    \n",
    "    l3_drop = tf.nn.dropout(l3, dropout_prob, seed=seed)\n",
    "    \n",
    "    output = tf.matmul(l3_drop, output_layer['weights']) +  output_layer['biases']\n",
    "    \n",
    "    regularizers = (tf.nn.l2_loss(hidden_1_layer['weights']) + tf.nn.l2_loss(hidden_1_layer['biases']) +\n",
    "                        tf.nn.l2_loss(hidden_2_layer['weights']) + tf.nn.l2_loss(hidden_2_layer['biases']) +\n",
    "                            tf.nn.l2_loss(hidden_3_layer['weights']) + tf.nn.l2_loss(hidden_3_layer['biases']) +\n",
    "                                tf.nn.l2_loss(output_layer['weights']) + tf.nn.l2_loss(output_layer['biases']))\n",
    "    \n",
    "    return output, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stat(x_range, trains, tests, vals, acc_0s, acc_1s):\n",
    "    \n",
    "    #plt.plot(x_range, trains,'-b', label='Training acc')\n",
    "    #plt.plot(x_range, vals,'-g', label='Validation acc')\n",
    "    #plt.plot(x_range, tests,'-y', label='Test acc')\n",
    "    plt.plot(x_range, acc_0s,'-r', label='Acc Class 0')\n",
    "    plt.plot(x_range, acc_1s,'-k', label='Acc Class 1')\n",
    "\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.0)\n",
    "\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_CV(x, lambda_):\n",
    "    \n",
    "    vals = []\n",
    "    trains = []\n",
    "    tests = []\n",
    "    x_range = []\n",
    "    \n",
    "    f1_vals = []\n",
    "    \n",
    "    acc_1s = []\n",
    "    acc_0s = []\n",
    "    \n",
    "    prediction, regularizers = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "    #log_loss = tf.contrib.losses.log_loss(predictions=prediction, labels=y)\n",
    "\n",
    "    #Eval this to get probability of [winning,losing]\n",
    "    prob = tf.nn.softmax(prediction)\n",
    "    \n",
    "    #learning rate can be passed\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost + lambda_ * regularizers)\n",
    "    \n",
    "    #metrics\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    false_prediction = tf.logical_not(correct_prediction)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "    #use for f1 score if needed\n",
    "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n",
    "    #acc for each class\n",
    "    class_0 = tf.where(tf.equal(tf.argmax(y, 1), 0))\n",
    "    class_0 = tf.reshape(class_0, [tf.shape(class_0)[0]])\n",
    "    pred_0 = tf.gather(prediction, class_0)\n",
    "    y_0 = tf.gather(y, class_0)\n",
    "    class_0_correct = tf.equal(tf.argmax(pred_0,1), tf.argmax(y_0,1))\n",
    "    acc_0 = tf.reduce_mean(tf.cast(class_0_correct, 'float'))\n",
    "    \n",
    "    class_1 = tf.where(tf.equal(tf.argmax(y, 1), 1))\n",
    "    class_1 = tf.reshape(class_1, [tf.shape(class_1)[0]])\n",
    "    pred_1 = tf.gather(prediction, class_1)\n",
    "    y_1 = tf.gather(y, class_1)\n",
    "    class_1_correct = tf.equal(tf.argmax(pred_1,1), tf.argmax(y_1,1))\n",
    "    acc_1 = tf.reduce_mean(tf.cast(class_1_correct, 'float'))\n",
    "    \n",
    "    display_step = 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            #epoch_loss = 0\n",
    "            fold_index = 0\n",
    "            \n",
    "            kf = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "            for train_index, test_index in kf.split(train_features, train_labels):\n",
    "                fold_index += 1\n",
    "                X_train, X_test = train_features[train_index], train_features[test_index]\n",
    "                y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: X_train, y: y_train})\n",
    "                #epoch_loss += c\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={ x: X_train, y: y_train})  \n",
    "                test_accuracy = accuracy.eval(feed_dict={ x: X_test, y: y_test})  \n",
    "                \n",
    "                # increase display_step after 10 iteration of same decimal\n",
    "                if epoch%(display_step*10) == 0 and epoch:\n",
    "                       display_step *= 10\n",
    "    \n",
    "                if (epoch%display_step == 0 or (epoch+1) == hm_epochs) and fold_index == 5:\n",
    "                    print('train:%.4f, test:%.4f,  epoch %d, fold %d' % (train_accuracy, test_accuracy, epoch, fold_index))\n",
    "\n",
    "                    #if (fold_index == kf.n_splits):\n",
    "                    validation_accuracy = accuracy.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "                    print ('val:%.2f' % (validation_accuracy))\n",
    "                    \n",
    "                    tp = true_positives.eval(feed_dict={ x: validation_features, y: validation_labels})   \n",
    "                    fp = false_positives.eval(feed_dict={ x: validation_features, y: validation_labels})  \n",
    "                    fn = false_negatives.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "\n",
    "                    precision = float(tp) / float(tp+fn + 0.0000000000001)\n",
    "                    recall = float(tp) / float(tp + fn + 0.0000000000001)\n",
    "                    F1_val = 2 * ( precision * recall ) / ( precision + recall + 0.0000000000001 )\n",
    "\n",
    "                    x_range.append(epoch)\n",
    "                    vals.append(validation_accuracy)\n",
    "                    trains.append(train_accuracy)\n",
    "                    tests.append(test_accuracy)\n",
    "                    f1_vals.append(F1_val)\n",
    "                    \n",
    "                    #print(validation_labels)\n",
    "                    #print(class_1.eval(feed_dict={ x: validation_features, y: validation_labels})  )\n",
    "\n",
    "                    acc_1s.append(acc_1.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    acc_0s.append(acc_0.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)        \n",
    "        \n",
    "        display_stat(x_range, trains, tests, vals, acc_0s, acc_1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.4868, test:0.4958,  epoch 0, fold 5\n",
      "val:0.46\n",
      "train:0.4857, test:0.4924,  epoch 1, fold 5\n",
      "val:0.46\n",
      "train:0.4879, test:0.4939,  epoch 2, fold 5\n",
      "val:0.45\n",
      "train:0.4892, test:0.4951,  epoch 3, fold 5\n",
      "val:0.47\n",
      "train:0.4907, test:0.4966,  epoch 4, fold 5\n",
      "val:0.47\n",
      "train:0.4886, test:0.4985,  epoch 5, fold 5\n",
      "val:0.46\n",
      "train:0.4960, test:0.5103,  epoch 6, fold 5\n",
      "val:0.47\n",
      "train:0.4988, test:0.5042,  epoch 7, fold 5\n",
      "val:0.50\n",
      "train:0.4934, test:0.5000,  epoch 8, fold 5\n",
      "val:0.47\n",
      "train:0.5012, test:0.4916,  epoch 9, fold 5\n",
      "val:0.47\n",
      "train:0.4982, test:0.5129,  epoch 10, fold 5\n",
      "val:0.49\n",
      "train:0.5133, test:0.4996,  epoch 20, fold 5\n",
      "val:0.53\n",
      "train:0.5265, test:0.5331,  epoch 30, fold 5\n",
      "val:0.50\n",
      "train:0.5322, test:0.5247,  epoch 40, fold 5\n",
      "val:0.56\n",
      "train:0.5391, test:0.5494,  epoch 50, fold 5\n",
      "val:0.53\n",
      "train:0.5497, test:0.5422,  epoch 60, fold 5\n",
      "val:0.55\n",
      "train:0.5598, test:0.5464,  epoch 70, fold 5\n",
      "val:0.56\n",
      "train:0.5578, test:0.5631,  epoch 80, fold 5\n",
      "val:0.58\n",
      "train:0.5634, test:0.5593,  epoch 90, fold 5\n",
      "val:0.55\n",
      "train:0.5635, test:0.5616,  epoch 100, fold 5\n",
      "val:0.59\n",
      "train:0.5858, test:0.5900,  epoch 200, fold 5\n",
      "val:0.60\n",
      "train:0.5900, test:0.5942,  epoch 300, fold 5\n",
      "val:0.60\n",
      "train:0.5876, test:0.5957,  epoch 400, fold 5\n",
      "val:0.60\n",
      "train:0.5940, test:0.5862,  epoch 449, fold 5\n",
      "val:0.61\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFyCAYAAADI0rFAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZmpfk//lxHfuQlXiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c46d953160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, feature_count])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "model_path = \"./tmp/model.ckpt\"\n",
    "save_dir = './tmp/'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "    \n",
    "L2_lambda_ = 1.5e-3\n",
    "train_neural_network_CV(x, L2_lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability test [[ 0.38545015  0.61454988]]\n"
     ]
    }
   ],
   "source": [
    "# Running a new session to predict based on model\n",
    "#TODO make sure it works and test\n",
    "prediction, regularizers = neural_network_model(x)\n",
    "#Eval this to get probability of [winning,losing]\n",
    "prob = tf.nn.softmax(prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     saver.restore(sess, model_path)\n",
    "    new_saver = tf.train.import_meta_graph(model_path + \".meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./tmp'))\n",
    "    \n",
    "    #test random sample from validation test\n",
    "    prob_test = validation_features[40].reshape((1,validation_features[0].shape[0]))\n",
    "    prob_value = prob.eval(feed_dict={ x:prob_test})  \n",
    "    print('probability test', prob_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32692872, -0.31204851, -0.32684987, -0.32688453, -0.32676454,\n",
       "        5.21943154,  0.50826235,  0.38402118, -0.31375633, -0.32673353,\n",
       "       -0.32671255, -0.32694888, -0.32693146, -0.31751632, -0.31180154,\n",
       "       -0.32656407, -0.32534424, -0.32692872, -0.31120542, -0.32684049,\n",
       "       -0.32687515, -0.32676819,  8.44878065,  0.94904214,  0.38893186,\n",
       "       -0.30494007, -0.32671912, -0.32670471, -0.32695061, -0.3269403 ,\n",
       "       -0.3168691 , -0.31103848, -0.32660903, -0.32516702, -0.32693602,\n",
       "       -0.31333459, -0.32688257, -0.32691723, -0.32682657,  3.58025366,\n",
       "        0.43102299,  0.67482447, -0.31463558, -0.32677403, -0.32673244,\n",
       "       -0.32695061, -0.32691869, -0.31811666, -0.31209724, -0.32695061,\n",
       "       -0.32602666, -0.32692689, -0.31192594, -0.32686835, -0.32690301,\n",
       "       -0.32682292,  5.78753747,  0.55221774,  0.5592773 , -0.30653076,\n",
       "       -0.3267972 , -0.32680522, -0.32692735, -0.32695061, -0.3169428 ,\n",
       "       -0.31257845, -0.32593181, -0.32630248, -0.3269351 , -0.31459225,\n",
       "       -0.32687734, -0.326912  , -0.32685019,  2.27890019,  0.26609751,\n",
       "        0.26042377, -0.31155673, -0.32688207, -0.32685833, -0.3269507 ,\n",
       "       -0.3269507 , -0.31912946, -0.31369608, -0.3269507 , -0.32537006,\n",
       "       -0.32693602, -0.31349467, -0.32688095, -0.32691561, -0.3268521 ,\n",
       "        4.10778626,  0.24002783,  0.40965818, -0.31650171, -0.32682474,\n",
       "       -0.32680249, -0.32695061, -0.32695061, -0.31767193, -0.31278076,\n",
       "       -0.32695061, -0.32695061, -0.3269351 , -0.31323972, -0.32687816,\n",
       "       -0.32691282, -0.32685539,  6.15701943,  0.5269805 ,  0.45189612,\n",
       "       -0.3139049 , -0.32673044, -0.32672022, -0.3269507 , -0.32694637,\n",
       "       -0.31819175, -0.31235719, -0.3269507 , -0.3269507 , -0.32693054,\n",
       "       -0.31278984, -0.32684381, -0.32687847, -0.32673718,  3.35458288,\n",
       "        0.55595   ,  0.40239613, -0.32191405, -0.32681197, -0.32680851,\n",
       "       -0.32694204, -0.32695061, -0.31696724, -0.31184769, -0.32506149,\n",
       "       -0.32470386, -0.32693164, -0.31240127, -0.32685428, -0.32688894,\n",
       "       -0.3267826 ,  4.66697398,  0.61270878,  0.39842881, -0.31358084,\n",
       "       -0.32678728, -0.32677411, -0.32692809, -0.32693484, -0.3163633 ,\n",
       "       -0.31168965, -0.32581041, -0.32581569, -0.32692325, -0.31527433,\n",
       "       -0.3268936 , -0.32692826, -0.32691048,  0.89425119, -0.05108737,\n",
       "        0.30523306, -0.31179533, -0.32690373, -0.32688603, -0.32694231,\n",
       "       -0.32692662, -0.32028214, -0.31461351, -0.32695061, -0.32489239])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
