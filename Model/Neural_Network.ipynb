{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../features/features_global.csv\", sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blue      7037\n",
       "purple    6696\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[:,0].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_nulls = df.apply(lambda row : \n",
    "          any([ e == (\"null\") for e in row ])\n",
    "       , axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>purple</td>\n",
       "      <td>3032929911</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>394.617</td>\n",
       "      <td>1.92308</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>2.78571</td>\n",
       "      <td>158539</td>\n",
       "      <td>21724.8</td>\n",
       "      <td>24917.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30202.8</td>\n",
       "      <td>531.632</td>\n",
       "      <td>5.44737</td>\n",
       "      <td>5.03158</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>-0.242105</td>\n",
       "      <td>260.316</td>\n",
       "      <td>413.189</td>\n",
       "      <td>-8.27895</td>\n",
       "      <td>1.35263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0           1         2        3        4         5        6    \\\n",
       "212  purple  3032929911  0.428571  394.617  1.92308  0.923077  2.78571   \n",
       "\n",
       "        7        8        9     ...         162      163      164      165  \\\n",
       "212  158539  21724.8  24917.4   ...     30202.8  531.632  5.44737  5.03158   \n",
       "\n",
       "          166       167      168      169      170      171  \n",
       "212  0.363158 -0.242105  260.316  413.189 -8.27895  1.35263  \n",
       "\n",
       "[1 rows x 172 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[212]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13733,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_nulls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[~no_nulls]\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>2984814498</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>423.95993</td>\n",
       "      <td>1.917431</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>133402.100</td>\n",
       "      <td>17926.000</td>\n",
       "      <td>16480.800</td>\n",
       "      <td>...</td>\n",
       "      <td>13711.350</td>\n",
       "      <td>114.10000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.685000</td>\n",
       "      <td>-0.402500</td>\n",
       "      <td>-0.352500</td>\n",
       "      <td>193.48500</td>\n",
       "      <td>332.70502</td>\n",
       "      <td>-10.030000</td>\n",
       "      <td>-7.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purple</td>\n",
       "      <td>3034035764</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>402.25280</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>137797.310</td>\n",
       "      <td>17697.053</td>\n",
       "      <td>17959.790</td>\n",
       "      <td>...</td>\n",
       "      <td>17441.264</td>\n",
       "      <td>302.21054</td>\n",
       "      <td>1.189474</td>\n",
       "      <td>1.642105</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.081579</td>\n",
       "      <td>200.77895</td>\n",
       "      <td>350.03687</td>\n",
       "      <td>4.418421</td>\n",
       "      <td>30.384210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purple</td>\n",
       "      <td>3036731710</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>421.79210</td>\n",
       "      <td>2.215569</td>\n",
       "      <td>1.215569</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>154794.270</td>\n",
       "      <td>23505.592</td>\n",
       "      <td>24949.682</td>\n",
       "      <td>...</td>\n",
       "      <td>29733.684</td>\n",
       "      <td>782.63160</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>-0.036842</td>\n",
       "      <td>-0.413158</td>\n",
       "      <td>223.42105</td>\n",
       "      <td>339.43683</td>\n",
       "      <td>-9.331579</td>\n",
       "      <td>-31.594736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purple</td>\n",
       "      <td>3018436026</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>384.25073</td>\n",
       "      <td>1.917526</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>2.368421</td>\n",
       "      <td>136257.270</td>\n",
       "      <td>17298.736</td>\n",
       "      <td>18882.053</td>\n",
       "      <td>...</td>\n",
       "      <td>14255.750</td>\n",
       "      <td>136.25000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>165.56500</td>\n",
       "      <td>310.27000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>65.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3026930091</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>398.31564</td>\n",
       "      <td>2.887755</td>\n",
       "      <td>1.887755</td>\n",
       "      <td>4.173913</td>\n",
       "      <td>125274.305</td>\n",
       "      <td>17986.130</td>\n",
       "      <td>22280.957</td>\n",
       "      <td>...</td>\n",
       "      <td>16022.895</td>\n",
       "      <td>226.68420</td>\n",
       "      <td>7.163158</td>\n",
       "      <td>6.894737</td>\n",
       "      <td>0.857895</td>\n",
       "      <td>0.323684</td>\n",
       "      <td>288.94210</td>\n",
       "      <td>461.35263</td>\n",
       "      <td>24.378946</td>\n",
       "      <td>56.265793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1         2          3         4         5         6    \\\n",
       "0    blue  2984814498  0.650000  423.95993  1.917431  0.917431  2.900000   \n",
       "1  purple  3034035764  0.526316  402.25280  2.000000  1.000000  2.157895   \n",
       "2  purple  3036731710  0.409091  421.79210  2.215569  1.215569  3.636364   \n",
       "3  purple  3018436026  0.473684  384.25073  1.917526  0.917526  2.368421   \n",
       "4    blue  3026930091  0.478261  398.31564  2.887755  1.887755  4.173913   \n",
       "\n",
       "          7          8          9      ...            162        163  \\\n",
       "0  133402.100  17926.000  16480.800    ...      13711.350  114.10000   \n",
       "1  137797.310  17697.053  17959.790    ...      17441.264  302.21054   \n",
       "2  154794.270  23505.592  24949.682    ...      29733.684  782.63160   \n",
       "3  136257.270  17298.736  18882.053    ...      14255.750  136.25000   \n",
       "4  125274.305  17986.130  22280.957    ...      16022.895  226.68420   \n",
       "\n",
       "        164       165       166       167        168        169        170  \\\n",
       "0  1.190000  1.685000 -0.402500 -0.352500  193.48500  332.70502 -10.030000   \n",
       "1  1.189474  1.642105  0.100000 -0.081579  200.77895  350.03687   4.418421   \n",
       "2  0.326316  0.773684 -0.036842 -0.413158  223.42105  339.43683  -9.331579   \n",
       "3  0.235000  0.405000 -0.330000 -0.022500  165.56500  310.27000   0.042500   \n",
       "4  7.163158  6.894737  0.857895  0.323684  288.94210  461.35263  24.378946   \n",
       "\n",
       "         171  \n",
       "0  -7.407500  \n",
       "1  30.384210  \n",
       "2 -31.594736  \n",
       "3  65.232500  \n",
       "4  56.265793  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13660, 172)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = df.replace(to_replace='null', value=0)\n",
    "#df = df.replace(to_replace='infinity', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Global constants\n",
    "seed = 7875\n",
    "validation_size = 750\n",
    "feature_count = df.shape[1] - 2\n",
    "\n",
    "#feed forward neural net\n",
    "n_nodes_hl1 = 300\n",
    "n_nodes_hl2 = 100\n",
    "n_nodes_hl3 = 50\n",
    "\n",
    "#cycles of feed forward + backprop on all K-folded samples\n",
    "hm_epochs = 2000\n",
    "\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = np.asarray(df.ix[:,2:feature_count+2])\n",
    "#standardize X\n",
    "meanX = np.mean(X, axis = 0)\n",
    "stdX = np.std(X, axis = 0)\n",
    "\n",
    "f = open('mean.pckl', 'wb')\n",
    "pickle.dump(meanX, f)\n",
    "f.close()\n",
    "\n",
    "f = open('std.pckl', 'wb')\n",
    "pickle.dump(stdX, f)\n",
    "f.close()\n",
    "\n",
    "X = (X - meanX) / stdX\n",
    "\n",
    "Y_1 = np.asarray(df.ix[:,0])\n",
    "Y_1 = [int(y == \"purple\") for y in Y_1]\n",
    "#one hot Y\n",
    "Y = np.zeros(shape=(len(Y_1), n_classes))\n",
    "Y[np.arange(len(Y_1)), Y_1] = 1\n",
    "    \n",
    "validation_features = X[:validation_size]\n",
    "validation_labels = Y[:validation_size]\n",
    "\n",
    "train_features = X[validation_size:]\n",
    "train_labels = Y[validation_size:]\n",
    "\n",
    "num_examples = train_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    \n",
    "    dropout_prob = 0.5\n",
    "    \n",
    "    hidden_1_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([feature_count, n_nodes_hl1], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl1]))\n",
    "    }\n",
    "    \n",
    "    hidden_2_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_nodes_hl2], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl2]))\n",
    "    }\n",
    "    \n",
    "    hidden_3_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl2, n_nodes_hl3], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_nodes_hl3]))\n",
    "    }\n",
    "    \n",
    "    output_layer = {\n",
    "        'weights': tf.Variable(tf.truncated_normal([n_nodes_hl1, n_classes], stddev=0.1, seed=seed)),\n",
    "        'biases': tf.Variable(tf.constant(1.0, shape=[n_classes]))\n",
    "    }\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu6(l1)\n",
    "    \n",
    "    l1_drop = tf.nn.dropout(l1, dropout_prob, seed=seed)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1_drop, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu6(l2)\n",
    "    \n",
    "    l2_drop = tf.nn.dropout(l2, dropout_prob, seed=seed)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.sigmoid(l3)\n",
    "    \n",
    "    l3_drop = tf.nn.dropout(l3, dropout_prob, seed=seed)\n",
    "    \n",
    "    output = tf.matmul(l1_drop, output_layer['weights']) +  output_layer['biases']\n",
    "    \n",
    "    regularizers = (tf.nn.l2_loss(hidden_1_layer['weights']) + tf.nn.l2_loss(hidden_1_layer['biases']) +\n",
    "                                tf.nn.l2_loss(output_layer['weights']) + tf.nn.l2_loss(output_layer['biases']))\n",
    "    \n",
    "    return output, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stat(x_range, trains, tests, vals, acc_0s, acc_1s):\n",
    "    \n",
    "    #plt.plot(x_range, trains,'-b', label='Training acc')\n",
    "    #plt.plot(x_range, vals,'-g', label='Validation acc')\n",
    "    #plt.plot(x_range, tests,'-y', label='Test acc')\n",
    "    plt.plot(x_range, acc_0s,'-r', label='Acc Class 0')\n",
    "    plt.plot(x_range, acc_1s,'-k', label='Acc Class 1')\n",
    "\n",
    "    plt.legend(loc='lower right', frameon=False)\n",
    "    plt.ylim(ymax = 1.1, ymin = 0.0)\n",
    "\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_neural_network_CV(x, lambda_):\n",
    "    \n",
    "    vals = []\n",
    "    trains = []\n",
    "    tests = []\n",
    "    x_range = []\n",
    "    \n",
    "    f1_vals = []\n",
    "    \n",
    "    acc_1s = []\n",
    "    acc_0s = []\n",
    "    \n",
    "    prediction, regularizers = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "    #log_loss = tf.contrib.losses.log_loss(predictions=prediction, labels=y)\n",
    "\n",
    "    #Eval this to get probability of [winning,losing]\n",
    "    prob = tf.nn.softmax(prediction)\n",
    "    \n",
    "    #learning rate can be passed\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost + lambda_ * regularizers)\n",
    "    \n",
    "    #metrics\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "    false_prediction = tf.logical_not(correct_prediction)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "    #use for f1 score if needed\n",
    "    true_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    false_positives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), True) )))\n",
    "    true_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(correct_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "    false_negatives = tf.reduce_sum(tf.to_int32(tf.logical_and(false_prediction, tf.equal(tf.argmax(tf.nn.softmax(y),1), False) )))\n",
    "\n",
    "    #acc for each class\n",
    "    class_0 = tf.where(tf.equal(tf.argmax(y, 1), 0))\n",
    "    class_0 = tf.reshape(class_0, [tf.shape(class_0)[0]])\n",
    "    pred_0 = tf.gather(prediction, class_0)\n",
    "    y_0 = tf.gather(y, class_0)\n",
    "    class_0_correct = tf.equal(tf.argmax(pred_0,1), tf.argmax(y_0,1))\n",
    "    acc_0 = tf.reduce_mean(tf.cast(class_0_correct, 'float'))\n",
    "    \n",
    "    class_1 = tf.where(tf.equal(tf.argmax(y, 1), 1))\n",
    "    class_1 = tf.reshape(class_1, [tf.shape(class_1)[0]])\n",
    "    pred_1 = tf.gather(prediction, class_1)\n",
    "    y_1 = tf.gather(y, class_1)\n",
    "    class_1_correct = tf.equal(tf.argmax(pred_1,1), tf.argmax(y_1,1))\n",
    "    acc_1 = tf.reduce_mean(tf.cast(class_1_correct, 'float'))\n",
    "    \n",
    "    display_step = 1\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            #epoch_loss = 0\n",
    "            fold_index = 0\n",
    "            \n",
    "            kf = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "            for train_index, test_index in kf.split(train_features, train_labels):\n",
    "                fold_index += 1\n",
    "                X_train, X_test = train_features[train_index], train_features[test_index]\n",
    "                y_train, y_test = train_labels[train_index], train_labels[test_index]\n",
    "                \n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: X_train, y: y_train})\n",
    "                #epoch_loss += c\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={ x: X_train, y: y_train})  \n",
    "                test_accuracy = accuracy.eval(feed_dict={ x: X_test, y: y_test})  \n",
    "                \n",
    "                # increase display_step after 10 iteration of same decimal\n",
    "                if epoch%(display_step*10) == 0 and epoch:\n",
    "                       display_step *= 10\n",
    "    \n",
    "                if (epoch%display_step == 0 or (epoch+1) == hm_epochs) and fold_index == 5:\n",
    "                    print('train:%.4f, test:%.4f,  epoch %d, fold %d' % (train_accuracy, test_accuracy, epoch, fold_index))\n",
    "\n",
    "                    #if (fold_index == kf.n_splits):\n",
    "                    validation_accuracy = accuracy.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "                    print ('val:%.2f' % (validation_accuracy))\n",
    "                    \n",
    "                    tp = true_positives.eval(feed_dict={ x: validation_features, y: validation_labels})   \n",
    "                    fp = false_positives.eval(feed_dict={ x: validation_features, y: validation_labels})  \n",
    "                    fn = false_negatives.eval(feed_dict={ x: validation_features, y: validation_labels})\n",
    "\n",
    "                    precision = float(tp) / float(tp+fn + 0.0000000000001)\n",
    "                    recall = float(tp) / float(tp + fn + 0.0000000000001)\n",
    "                    F1_val = 2 * ( precision * recall ) / ( precision + recall + 0.0000000000001 )\n",
    "\n",
    "                    x_range.append(epoch)\n",
    "                    vals.append(validation_accuracy)\n",
    "                    trains.append(train_accuracy)\n",
    "                    tests.append(test_accuracy)\n",
    "                    f1_vals.append(F1_val)\n",
    "                    \n",
    "                    #print(validation_labels)\n",
    "                    #print(class_1.eval(feed_dict={ x: validation_features, y: validation_labels})  )\n",
    "\n",
    "                    acc_1s.append(acc_1.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    acc_0s.append(acc_0.eval(feed_dict={ x: validation_features, y: validation_labels}))\n",
    "                    \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)        \n",
    "        \n",
    "        display_stat(x_range, trains, tests, vals, acc_0s, acc_1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.4832, test:0.4915,  epoch 0, fold 5\n",
      "val:0.47\n",
      "train:0.4871, test:0.4926,  epoch 1, fold 5\n",
      "val:0.44\n",
      "train:0.4862, test:0.4946,  epoch 2, fold 5\n",
      "val:0.47\n",
      "train:0.4938, test:0.4888,  epoch 3, fold 5\n",
      "val:0.48\n",
      "train:0.4906, test:0.4930,  epoch 4, fold 5\n",
      "val:0.47\n",
      "train:0.4928, test:0.4903,  epoch 5, fold 5\n",
      "val:0.47\n",
      "train:0.5026, test:0.4988,  epoch 6, fold 5\n",
      "val:0.48\n",
      "train:0.4992, test:0.5229,  epoch 7, fold 5\n",
      "val:0.50\n",
      "train:0.5071, test:0.5116,  epoch 8, fold 5\n",
      "val:0.46\n",
      "train:0.5138, test:0.5101,  epoch 9, fold 5\n",
      "val:0.53\n",
      "train:0.5075, test:0.5248,  epoch 10, fold 5\n",
      "val:0.50\n",
      "train:0.5306, test:0.5376,  epoch 20, fold 5\n",
      "val:0.51\n",
      "train:0.5400, test:0.5391,  epoch 30, fold 5\n",
      "val:0.54\n",
      "train:0.5280, test:0.5263,  epoch 40, fold 5\n",
      "val:0.53\n",
      "train:0.5390, test:0.5380,  epoch 50, fold 5\n",
      "val:0.55\n",
      "train:0.5346, test:0.5248,  epoch 60, fold 5\n",
      "val:0.53\n",
      "train:0.5344, test:0.5500,  epoch 70, fold 5\n",
      "val:0.53\n",
      "train:0.5308, test:0.5453,  epoch 80, fold 5\n",
      "val:0.49\n",
      "train:0.5393, test:0.5662,  epoch 90, fold 5\n",
      "val:0.53\n",
      "train:0.5419, test:0.5542,  epoch 100, fold 5\n",
      "val:0.51\n",
      "train:0.5540, test:0.5434,  epoch 200, fold 5\n",
      "val:0.53\n",
      "train:0.5605, test:0.5736,  epoch 300, fold 5\n",
      "val:0.52\n",
      "train:0.5664, test:0.5782,  epoch 400, fold 5\n",
      "val:0.56\n",
      "train:0.5814, test:0.5887,  epoch 500, fold 5\n",
      "val:0.58\n",
      "train:0.5838, test:0.6088,  epoch 600, fold 5\n",
      "val:0.56\n",
      "train:0.5912, test:0.6042,  epoch 700, fold 5\n",
      "val:0.61\n",
      "train:0.5916, test:0.6119,  epoch 800, fold 5\n",
      "val:0.58\n",
      "train:0.5906, test:0.6181,  epoch 900, fold 5\n",
      "val:0.59\n",
      "train:0.5896, test:0.6170,  epoch 1000, fold 5\n",
      "val:0.58\n",
      "train:0.6362, test:0.6538,  epoch 1999, fold 5\n",
      "val:0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFyCAYAAAAu+3oEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzRFARgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fd96773f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = tf.placeholder('float', [None, feature_count])\n",
    "y = tf.placeholder('float', [None, n_classes])\n",
    "\n",
    "model_path = \"./tmp2/model.ckpt\"\n",
    "save_dir = './tmp2/'\n",
    "if not os.path.isdir(saqve_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "    \n",
    "L2_lambda_ = 1.5e-3\n",
    "train_neural_network_CV(x, L2_lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability test [[ 0.38545015  0.61454988]]\n"
     ]
    }
   ],
   "source": [
    "# Running a new session to predict based on model\n",
    "#TODO make sure it works and test\n",
    "prediction, regularizers = neural_network_model(x)\n",
    "#Eval this to get probability of [winning,losing]\n",
    "prob = tf.nn.softmax(prediction)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     saver.restore(sess, model_path)\n",
    "    new_saver = tf.train.import_meta_graph(model_path + \".meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./tmp2'))\n",
    "    \n",
    "    #test random sample from validation test\n",
    "    prob_test = validation_features[40].reshape((1,validation_features[0].shape[0]))\n",
    "    prob_value = prob.eval(feed_dict={ x:prob_test})  \n",
    "    print('probability test', prob_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32692872, -0.31204851, -0.32684987, -0.32688453, -0.32676454,\n",
       "        5.21943154,  0.50826235,  0.38402118, -0.31375633, -0.32673353,\n",
       "       -0.32671255, -0.32694888, -0.32693146, -0.31751632, -0.31180154,\n",
       "       -0.32656407, -0.32534424, -0.32692872, -0.31120542, -0.32684049,\n",
       "       -0.32687515, -0.32676819,  8.44878065,  0.94904214,  0.38893186,\n",
       "       -0.30494007, -0.32671912, -0.32670471, -0.32695061, -0.3269403 ,\n",
       "       -0.3168691 , -0.31103848, -0.32660903, -0.32516702, -0.32693602,\n",
       "       -0.31333459, -0.32688257, -0.32691723, -0.32682657,  3.58025366,\n",
       "        0.43102299,  0.67482447, -0.31463558, -0.32677403, -0.32673244,\n",
       "       -0.32695061, -0.32691869, -0.31811666, -0.31209724, -0.32695061,\n",
       "       -0.32602666, -0.32692689, -0.31192594, -0.32686835, -0.32690301,\n",
       "       -0.32682292,  5.78753747,  0.55221774,  0.5592773 , -0.30653076,\n",
       "       -0.3267972 , -0.32680522, -0.32692735, -0.32695061, -0.3169428 ,\n",
       "       -0.31257845, -0.32593181, -0.32630248, -0.3269351 , -0.31459225,\n",
       "       -0.32687734, -0.326912  , -0.32685019,  2.27890019,  0.26609751,\n",
       "        0.26042377, -0.31155673, -0.32688207, -0.32685833, -0.3269507 ,\n",
       "       -0.3269507 , -0.31912946, -0.31369608, -0.3269507 , -0.32537006,\n",
       "       -0.32693602, -0.31349467, -0.32688095, -0.32691561, -0.3268521 ,\n",
       "        4.10778626,  0.24002783,  0.40965818, -0.31650171, -0.32682474,\n",
       "       -0.32680249, -0.32695061, -0.32695061, -0.31767193, -0.31278076,\n",
       "       -0.32695061, -0.32695061, -0.3269351 , -0.31323972, -0.32687816,\n",
       "       -0.32691282, -0.32685539,  6.15701943,  0.5269805 ,  0.45189612,\n",
       "       -0.3139049 , -0.32673044, -0.32672022, -0.3269507 , -0.32694637,\n",
       "       -0.31819175, -0.31235719, -0.3269507 , -0.3269507 , -0.32693054,\n",
       "       -0.31278984, -0.32684381, -0.32687847, -0.32673718,  3.35458288,\n",
       "        0.55595   ,  0.40239613, -0.32191405, -0.32681197, -0.32680851,\n",
       "       -0.32694204, -0.32695061, -0.31696724, -0.31184769, -0.32506149,\n",
       "       -0.32470386, -0.32693164, -0.31240127, -0.32685428, -0.32688894,\n",
       "       -0.3267826 ,  4.66697398,  0.61270878,  0.39842881, -0.31358084,\n",
       "       -0.32678728, -0.32677411, -0.32692809, -0.32693484, -0.3163633 ,\n",
       "       -0.31168965, -0.32581041, -0.32581569, -0.32692325, -0.31527433,\n",
       "       -0.3268936 , -0.32692826, -0.32691048,  0.89425119, -0.05108737,\n",
       "        0.30523306, -0.31179533, -0.32690373, -0.32688603, -0.32694231,\n",
       "       -0.32692662, -0.32028214, -0.31461351, -0.32695061, -0.32489239])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
